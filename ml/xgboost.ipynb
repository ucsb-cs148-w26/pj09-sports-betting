{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "bd19c368",
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import optuna\n",
        "from pathlib import Path\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "adb9bcd6",
      "metadata": {},
      "outputs": [],
      "source": [
        "gamesDF = pd.read_csv('./datasets/training_dataset_l10_wp.csv')\n",
        "gamesDF = gamesDF.drop(columns=['HOME_L10_LOSSES', 'AWAY_L10_LOSSES', 'PERIOD', 'POINT_DIFF'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "8238324d",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = gamesDF[['SECONDS_REMAINING','HOME_SCORE','AWAY_SCORE','HOME_WINS', 'HOME_LOSSES', 'AWAY_WINS', 'AWAY_LOSSES', 'HOME_L10_WINS', 'AWAY_L10_WINS']] \n",
        "y = gamesDF['HOME_WIN']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "fff9bef1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2026-02-10 10:43:04,806]\u001b[0m A new study created in memory with name: no-name-3bcf4e44-d5a4-4251-b8a3-67685e82a649\u001b[0m\n",
            "\u001b[32m[I 2026-02-10 10:43:19,473]\u001b[0m Trial 0 finished with value: 0.4513880505477987 and parameters: {'n_estimators': 669, 'max_depth': 2, 'learning_rate': 0.06336610670711006, 'subsample': 0.9422679645388454, 'colsample_bytree': 0.7462234726096552, 'reg_lambda': 0.02994972186733143, 'reg_alpha': 0.04147623480440184, 'min_child_weight': 137, 'gamma': 0.5193928008977384}. Best is trial 0 with value: 0.4513880505477987.\u001b[0m\n",
            "\u001b[32m[I 2026-02-10 10:43:28,225]\u001b[0m Trial 1 finished with value: 0.4689162788732399 and parameters: {'n_estimators': 318, 'max_depth': 2, 'learning_rate': 0.07017531088150633, 'subsample': 0.6355474543932951, 'colsample_bytree': 0.7937608358864334, 'reg_lambda': 1.0262383951777676, 'reg_alpha': 5.422973240692295, 'min_child_weight': 146, 'gamma': 2.7551338164701367}. Best is trial 0 with value: 0.4513880505477987.\u001b[0m\n",
            "\u001b[32m[I 2026-02-10 10:43:50,221]\u001b[0m Trial 2 finished with value: 0.44480473020250255 and parameters: {'n_estimators': 752, 'max_depth': 2, 'learning_rate': 0.07013105594416966, 'subsample': 0.826251705866438, 'colsample_bytree': 0.7773751002654127, 'reg_lambda': 1.9661340201910718, 'reg_alpha': 0.12946158488895915, 'min_child_weight': 296, 'gamma': 1.775880913717799}. Best is trial 2 with value: 0.44480473020250255.\u001b[0m\n",
            "\u001b[32m[I 2026-02-10 10:44:11,487]\u001b[0m Trial 3 finished with value: 0.4462284043393493 and parameters: {'n_estimators': 594, 'max_depth': 2, 'learning_rate': 0.07461172578514709, 'subsample': 0.8039876947788199, 'colsample_bytree': 0.808778006077142, 'reg_lambda': 9.191910589595025, 'reg_alpha': 0.008009887487980984, 'min_child_weight': 55, 'gamma': 0.6554666705134025}. Best is trial 2 with value: 0.44480473020250255.\u001b[0m\n",
            "\u001b[32m[I 2026-02-10 10:44:31,500]\u001b[0m Trial 4 finished with value: 0.39092068297171356 and parameters: {'n_estimators': 521, 'max_depth': 4, 'learning_rate': 0.061200500952725015, 'subsample': 0.9330262359837351, 'colsample_bytree': 0.6477852219870596, 'reg_lambda': 0.002291261713927826, 'reg_alpha': 0.20599208702049462, 'min_child_weight': 193, 'gamma': 3.9571590189846457}. Best is trial 4 with value: 0.39092068297171356.\u001b[0m\n",
            "\u001b[32m[I 2026-02-10 10:44:45,548]\u001b[0m Trial 5 finished with value: 0.47340449913515115 and parameters: {'n_estimators': 577, 'max_depth': 2, 'learning_rate': 0.034676880842964386, 'subsample': 0.9487382132294677, 'colsample_bytree': 0.8329356981302759, 'reg_lambda': 0.0029319071371464627, 'reg_alpha': 0.097017162605838, 'min_child_weight': 181, 'gamma': 0.8537434765370845}. Best is trial 4 with value: 0.39092068297171356.\u001b[0m\n",
            "\u001b[32m[I 2026-02-10 10:44:55,686]\u001b[0m Trial 6 finished with value: 0.47798493932807384 and parameters: {'n_estimators': 410, 'max_depth': 2, 'learning_rate': 0.03847445995723931, 'subsample': 0.6951618663390317, 'colsample_bytree': 0.9961260598114154, 'reg_lambda': 0.03936677592494777, 'reg_alpha': 3.564486388777748, 'min_child_weight': 152, 'gamma': 3.068248083405231}. Best is trial 4 with value: 0.39092068297171356.\u001b[0m\n",
            "\u001b[32m[I 2026-02-10 10:45:07,010]\u001b[0m Trial 7 finished with value: 0.4590492593182115 and parameters: {'n_estimators': 436, 'max_depth': 3, 'learning_rate': 0.03539713834652557, 'subsample': 0.741833963077302, 'colsample_bytree': 0.8427561451930754, 'reg_lambda': 5.401445516055583, 'reg_alpha': 0.01760552260571908, 'min_child_weight': 288, 'gamma': 4.106350029360957}. Best is trial 4 with value: 0.39092068297171356.\u001b[0m\n",
            "\u001b[32m[I 2026-02-10 10:45:24,692]\u001b[0m Trial 8 finished with value: 0.4451577442295178 and parameters: {'n_estimators': 540, 'max_depth': 2, 'learning_rate': 0.07630907628294793, 'subsample': 0.8942521703759119, 'colsample_bytree': 0.9953112160304012, 'reg_lambda': 3.7990862870344526, 'reg_alpha': 0.13085637804102018, 'min_child_weight': 145, 'gamma': 1.6622574049923715}. Best is trial 4 with value: 0.39092068297171356.\u001b[0m\n",
            "\u001b[32m[I 2026-02-10 10:45:36,657]\u001b[0m Trial 9 finished with value: 0.465317240394052 and parameters: {'n_estimators': 555, 'max_depth': 2, 'learning_rate': 0.040611644391297025, 'subsample': 0.9264284671510246, 'colsample_bytree': 0.9194276800368169, 'reg_lambda': 3.9040584449410227, 'reg_alpha': 0.022864323058815608, 'min_child_weight': 139, 'gamma': 1.0038836078037494}. Best is trial 4 with value: 0.39092068297171356.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 521, 'max_depth': 4, 'learning_rate': 0.061200500952725015, 'subsample': 0.9330262359837351, 'colsample_bytree': 0.6477852219870596, 'reg_lambda': 0.002291261713927826, 'reg_alpha': 0.20599208702049462, 'min_child_weight': 193, 'gamma': 3.9571590189846457}\n"
          ]
        }
      ],
      "source": [
        "def save_model(model, model_path_name):\n",
        "    model_path = Path(model_path_name)\n",
        "    joblib.dump(model, model_path)\n",
        "    print(f\"Model saved to {model_path.absolute()}\")\n",
        "\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    test_size=0.2,\n",
        "    stratify=y_train,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 800),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 4),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.08, log=True),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        \"eval_metric\": \"logloss\",\n",
        "        \"n_jobs\": -1,\n",
        "        \"early_stopping_rounds\": 50,\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 50, 300),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0.5, 5.0),\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        verbose=False,\n",
        "    )\n",
        "    y_proba = model.predict_proba(X_val)[:, 1]\n",
        "    return log_loss(y_val, y_proba)\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "ceefc33b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /Users/lemons/Documents/universidad/cs/pj09-sports-betting/ml/xgboost.joblib\n"
          ]
        }
      ],
      "source": [
        "bst = XGBClassifier(**study.best_params)\n",
        "bst.fit(X_train, y_train)\n",
        "save_model(bst, 'xgboost.joblib')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
