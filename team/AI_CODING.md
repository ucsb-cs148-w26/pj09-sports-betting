### Alvin Chan

For my AI coding experiment, I tried to create an entire mobile app strictly using the Gemini 3.0 Pro model. The main function of my app for the experiment was to have an easy way for users to keep track of clothes in their wardrobe and have a way for them to pit it up for sale. I first prompted the bot to give me an effective prompt format for it to generate code and then filled out the blanks in the format it gave me. The first few iterations of the app contained the main function of having a virtual "closet," but it didn't allow images of the clothes to be uploaded/searched online, which I think is important. I think this shows the importance on being very clear with my words when prompting something. I believe Gemini Pro 3.0 will be very useful for coding my projects as it produces working code relatively quickly and is able to understand what it's prompted to do well. To ensure the AI output was correct, I made sure to run through all the code and ensure it is written with correct logic and syntax. I also had to check the functionalities of the app with unit tests.

### Logan Melgoza

For my AI codding experiemnt, I wanted to see how effective AI is for taking an existing codebase and creating useful documentation for it. The model I used was GPT-5.3-Codex with medium resoning with fule IDE context inside of VS Code. Specifically, I had asked the agent to go into the backend directory and create documentation that is not only useful to be documented overall, but is a quick way that our frontend team can understand the backend and interact with it. What resulted from this was a complete detailed documentation of our our endpoints, our databse, backend architecture, frontend-contracts, known-issues, and even documentation of running the backend locally. Personally, I think this was very useful because documention can take a lot of time out of someones day. So, being able to have a tool that can generate you useful documentation with the context of everything you have done is very helpful. It is especially helpful when you have a short timeframe like our class does. All I hade to do was go through the documentation and ensure that it sounded like it was actually refering to things properly in our code base, and it did a good job of that without me having to make additionaly prompts or edits. Overall, the only downside I can see is that if there is a large and complicated code base it may be hard for a model to comprehend or may take a lot of time.

### Jay Yeung

For my AI coding experiment, I wanted to prototype different UI possibilities for a new web app using the ChatGPT-5.2 model. The goal was to experiment with different UI's for a web app designed to allow users to define long-term objectives, and use AI to break them into trackable milestones in a roadmap that matches the timetable the user set for the goal. I specifically prompted the model to generate different layouts and ideas. This gave many different layout options, such as a tree-based milestone view with each long-term goal being broken into subgoals, a dependency graph visualization that gives daily tasks/goals to accomplish these milestones, and a dashboard-style progression that shows a % completion, streaks, and overdue tasks. The AI helped with giving many component structures and the pros and cons of each layout option. I also further used it to give a Firebase schema for these goals. This was very useful because it can save a lot of time in testing different structures, and generate many different ideas for a singular web app. It also provided the pros and cons, and can help with deciding the final structure you may want for a web application. I found each of the designs very unique with different pros and cons, and I think ChatGPT can be very helpful in producing quick code so I can actually manually experiment with UIs and test which ones work best for me as a user. To ensure correctness, I had to make sure to review the code and locally test the logic to ensure it worked as expected. I also had to run a few tests to make sure the logic was correct.

### Kevin Yang

The AI coding tool I utilized was Cursor, where I instructed its agent (set as Auto) to write code that stores the number of games that each team has won in their last 10 games, which would be used as additional features when training models. Instead of relying on calling an API to get each team's win record in their last 10 games on a game-by-game basis, I figured it would be reasonable to let an AI manually collect each team's record in their last 10 games during the scraping phase, as the data already contained information about which teams played and whether they were home and away in a chronological fashion. This way, each team's L10 wins could be cumulated automatically, and likely saved unnecessary API calls and data synchronization between the existing features and new L10 data. The AI was extremely useful in producing the desired results, and I will be using this tool in the future to automate tedious tasks or generate multiple ideas in how a task can be approached. I still recognize that the important thing is to still understand how and why the AI written code works, and not blindly trust its results. To reach this end, I examined the CSV dataset file that it ended up generating and confirmed that the HOME_L10_WINS and AWAY_L10_WINS were betweeen the values of 0 and 10. I also picked an arbitrary game within the dataset and Googled each team's L10 wins before that point to confirm that the AI L10 wins cumulation logic was correct.
